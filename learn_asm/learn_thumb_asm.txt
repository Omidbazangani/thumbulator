
This is a work in progress, very rough at the moment, expect errors
and mispellings and rewrites.


The prerequisite for this tutorial is some level of programming experience
using a higher level language.  This tutorial is not going to show the
basics of programming common to all languages.  This is for folks who
have some programming experience and want to learn assembly language
or want to learn assembly language for this platform (ARM's thumb
instruction set).  I highly recommend experience programming in C, the
tools (simulator and assembler) are written in C, C may be used to explain
what is going in in the assembly language, etc.  You also need to have
experience with binary representation of numbers, hexadecimal as well
as decimal.  Also a working knowledge of twos complement is required.

This tutorial will touch on twos complement and things like a carry
flag and overflow, etc, but not go into great detail.  Perhaps later
an appendix or separate document will cover those topics, for now
you may wish to try my learn asm tutorial that is part of my lsasim project
http://github.com/dwelch67/lsasim
lsa is an instruction set I developed which resembled features from others
specifically for educational purposes.  A first instruction set for
teaching assembly language for example.  Once learning the lsa instruction
set transitioning to ARM (32 bit or thumb instructions) should be relatively
easy.

If you dont have basic programming experience you might try these
http://learnpythonthehardway.org and then perhaps
http://c.learncodethehardway.org.  Please do not judge these books by
their title,  it is not a bad method at all for teaching.

A little bit about ARM and why thumb might be interesting or important.
ARM is an acronym that has changed its definition over time.  Acorn
RISC Machine and Advanced RISC Machine being two.  The family of
processors were derived from a 32 bit machine.  The instructions were
fixed at 32 bits.  The popular ARM7TDMI processor core included a 16
bit subset to the ARM instruction set.  Affectionately named the
thumb instruction set.  What I will call "all thumb variant" or
"ARM7TDMI" or "ARMv4T" thumb instructions are basically the original
16 bit instructions supported in the ARMV7TDMI (ARMv4T architecture).

You are going to want/need a manual from ARM.  Start at
http://infocenter.arm.com along the left side expand ARM Architecture
then expand Reference Manuals.  Then expand the ARMv5 Architectur
Reference Manual.  On the right/middle of the page click on the PDF
version link.  You will need to create an ARM account if you dont have
one.  No cost other than a name and email address.  The thumb simulator
and assembler support most of the instructions in the thumb chapter
of this document.

With respect to the learn code the hard way series the idea here will
be to present you with example programs.  It is in your best interest
to type that code in your editor yourself without cutting and pasting.
You learn to actually write the programs this way and you learn to
debug typos and other syntax issues this way which is as essential
to learning a new language as learning the mnemonics and rules.  Each
example will show the expected output from the thumbulator instruction
set simulator, and a discussion about the program and what you should
learn from it.

Lets dig in:

---------------------------------------------------------------------
Lesson 0:  Building tools and first simulation

This is the exception to the rule of having code and output, this lesson
is to get you up and running.

Thumbulator is a simple, hopefully portable, single file program that
should compile most anywhere.  The makefile is made for a linux/unix
environment with gnu tools.  Microsft Visual C, llvm/clang, etc should
all be able to handle this file and create a binary.

gcc thumbulator.c -o thumbulator
clang thumbulator.c -o thumbulator
cl thumbulator.c
etc

There are a couple of ways to "see" what thumbulator is doing, there are
defines at the top of the source file DBUG, DISS, etc.  Making those
non-zero and recompiling thumbulator it will dump out a lot more stuff
while it runs.  The simulator takes a brute force approach, in no way
is it designed for performance, it is designed to be accurate, readable
and understandable.  An average programmer should not have any problem
reading and understanding that code, in particular seeing what the
debug defines do and adding their own where needed.   The second method
for debugging is to create vcd (value change dump) files, which are used
in the hardware design industry to see logic signals as it ran in a
simulation.  Tacking --vcd onto the end of the thumbulator command line
will create an output.vcd file which you can view with tools like gtkwave.
Gtkwave you would have to go find or build and is not required for these
lessons.   If you choose to though it may greatly help you debug your
program.  Be careful though if you leave thumbulator running indefinitely
with vcd output it can/will create a huge file.

Until further notice, enable these two flags and leave the others
disabled, this way your output will match the output in this tutorial.

#define DBUGFETCH   0
#define DBUGRAM     0
#define DBUGRAMW    0
#define DBUGREG     1
#define DBUG        0
#define DISS        1

And re-build the thumbulator program.

I have created and provided a thumb assembler so that you dont have
to get your hands dirty finding or building a toolchain.  These lessons
assume the tas thumb assembler that comes with thumbulator is used.
Later gnu binutils differences may be discussed.

In the tas directory, same story, the makefile is related to gnu tools
on a linux/unix system.  tas is a single file, ideally portable program

gcc tas.c -o tas
clang tas.c -o tas
etc

For each lesson there will be some assembly language code between
lines that look like this: ---- lesson01.s ---- The primary task (other
than learning) is to re-type the lines of that program into a text
file on a text editor.  Do not include the ---- lesson01.s ---- lines
themselves.  It is time to perform this typing task for lesson 0:

---- lesson00.s ----
.word 0x40080000
.word 0x11
.word 0
.word 0
.hword 0xDEAD
---- lesson00.s ----

% tas lesson00.s

tas output:
assemble(0)
0x00000000: 0x0000 data
0x00000002: 0x4008 data
0x00000004: 0x0011 data
0x00000006: 0x0000 data
0x00000008: 0x0000 data
0x0000000A: 0x0000 data
0x0000000C: 0x0000 data
0x0000000E: 0x0000 data
0x00000010: 0xDEAD data


% thumbulator lesson.s.bin

thumbulator output:

read_register(15)=0x00000012
write_register(15,0x00000014)
0x0000000F: 0xDEAD invalid instruction 0x00000014 0xDEAD

instructions 1
fetches      1
reads        0
writes       0
memcycles    1
systick_ints 0


For each lesson follow this model of using tas to assemble the program
and thumbulator to run the binary created.  tas will tack on a .bin
name to what you feed it, feed it bob.s you get bob.s.bin.

The lessons will typically only show the relevant thumbulator output.

So what is happening here?

tas is a bit verbose about what it is doing, sorting out labels and
then dumps a disassembly of what it assembled.  I tried to clean room
the disassembly from the assembly so that I could catch my own mistakes
but some will no doubt get through.  Please help make the tools better
by reporting issues.

Assemblers will have some sort of directive that you can use to place
raw data into the binary.  This one uses .word which is the same/similar
to the gnu assembler in binutils (gas).  In the ARM world a "word" is
32 bits, a "half word" is 16 and a "byte" is 8 bits.  The computer you
are likely reading/running this on is an x86 where a word is 16 bits
and a double word is 32 bits.  To operate at this level you need to be
able to adapt to the lingo and/or translate.  The .word directives
here are used to place 32 bit values in the binary, what and why will
be explained in a second.  The .hword is there to place a 16 bit value
the top 8 bits of that value 0xDE imply an undefined instruction, this
half word is placed in this program to be executed as an instruction
and is there specifically to stop the simulator.  I didnt want the
simulation to run forever.

This is the first thing to learn here
assembly is intimately related to machine code.  The bits and bytes
that are interpreted by the processor to make it actually do stuff.
Unlike high level programming languages where there are a lot of rules,
a variable might have a definition of signed or unsigned or a pointer
to something.  These are all an illusion created in reference to the
syntax/rules of that language and dont have much of a basis in reality
in the processor.  its just bits, the processor doesnt know or care
for a very brief moment a set of bits might be considered an input
or an output of an add operation, basically data.  That add operation
may have been computing an address and the next instruction that uses
the output bits from the add, a sum, data, now defines those bits as
an address, a pointer into memory.  After the read or write of memory
instruction has finished those bits are just bits again, no meaning.

Assembly doesnt or at least shouldnt prevent you from just sticking bits
in wherever you like.  Say for example you want to use the tas assembler
but really really feel the need to insert an arm instruction or a
thumb2 instruction whose assembly syntax is not supported by tas, you
can just stick the instruction bytes right into the code using .word or
.hword or .byte, nothing will stop you from doing that and nothing will
stop you from trying to execute that on whatever processor you try to
execute it on.  On thumulator it wont work but take the output of tas
to another ARM processor and it might.

The point of assembly language is that you are writing machine code
for the processor in a human readable/writeable form.  You could just
type in bits or bytes, but it is a lot harder to read and maintain

0xE7FE

than it is to read and maintain

hang:
    b hang

Although the thumbulator project strives to be the older, more pure
original thumb instruciton set, it uses the modern Cortex-M series
exception table.  The Cortex-M series of ARM cores are basically thumb
only cores.  With a traditional 32 bit ARM processor the exception
table, the well known (to hardware and software) addresses that are used
to boot the processor and handle interrupts, etc will contain 32 bit
ARM instructions, the processor simply starts executing at that address.
The Cortex-M method is a bit more traditional, it has a table of addresses
these are addresses to the code that handles that event, reset, data
abort, etc.  So there is one level of indirection for the Cortex-M, go
to the exception table, read an address, then go to that address and
start executing code.  The traditional ARM method is without the
indirection, just start executing code in the exception table.

This is a thumb only processor (simulator) it will not execute full sized
ARM instructions, only thumb.  Other than memory space and peripheral
differences you can take code that runs here and run it on real Cortex-M
hardware.

The vector or exception table in a Cortex-M processor starts at address
zero (0x00000000).  The first 32 bit location is used to pre-initialize
the stack pointer.  This allows for example to have handlers, including
reset, written in C or some other compiled language without asm support
code.   The compiler must conform to the hardwares rules in order to
simply put a C function address in the exception table.  You are welcome
to initialize the stack pointer the old fashioned way, nothing prevents
you from doing that.

this example uses

.word 0x40080000

As the initializer for the stack pointer.  This was determined knowing
the virtual ram/memory space of the thumbulator simulated processor.

The second word in the processors memory space for a Cortex-M is the
address to the reset handler.  For this example the value 0x11 is
placed in that location.  If this is not a strange value it should
be.  First off this is a fixed 16 bit width instruction set, and the
assembler dumps, etc do not use odd addresses.  The ARM processors that
can switch modes between ARM and thumb use the lsbit of the address
when using a specific instruction to indicate the mode being branched
to.  When the lsbit is set the branch is to a thumb code, when clear
the destination is ARM instructions.  To conform with that convention
the hander is at address 0x10 and is thumb code so the address 0x11 is
used.

Real Cortex-M processors have many vectors in the vector table, dozens
to hundreds...really.  On real Cortex-M processors as well as thumbulator
if you are not using those vectors you can use that address space
for code.  I have used a simple address like 0x10, which is 16 bytes or
4 32bit words.  So there are two more .word's after the .word 0x11 used
as padding and then our code starts.

So looking at the lesson0 code, the first line of code is a .word
directive for the stack pointer load value.  The second line is a .word
that tells the processor on reset start executing code at address 0x0010.
We have two more .word lines to add some padding so that we have four
words of header (16 bytes, bytes at addresses 0x00 to 0x0F, one short of
0x10).  Then we see a
.hword 0xDEAD
.hword means halfword or 16 bits, place this 16 bit value in memory
at this point in the program.  So the processor is going to try to
start executing whatever this 0xDEAD machine code instruction is.
Turns out it just happens to be an undefined instruction as far as the
thumbulator processor is concerned and unlike real processors that
call an undefined instruction exception, this processor halts, by design.
Placing an undefined instruction here was intentional.

---------------------------------------------------------------------
Lesson 1:  Load some immediates

---- lesson00.s ----
.word 0x40080000
.word 0x11
.word 0
.word 0
.hword 0xDEAD
---- lesson00.s ----









































A little arm history
32 bit ARM vs 16 bit thumb
thumb vs thumb2
most portable arm instruction set
differences between arm and thumb





These instructions can all be mapped directly to 32 bit ARM instructions.
I can imagine how this must have worked inside the processor, in thumb
mode the processor basically converts these instructions during the
decode and feeds the converted 32 bit ARM instructions to the ARM
processor.  It does not go the other way there is not a thumb instruction
to go with every ARM instruction.  The more modern Cortex-M series of
processors do not at all support the 32 bit, non-thumb ARM7 like
instructions, they are thumb only machines, my guess is they are not
ARM 32 bit cores with a thumb to ARM translator but instead designed
from the ground up to be thumb machines.

You will see the term thumb-2 thrown about with respect to ARM
processors.  Just like the ARM instruction set itself (lets say from the
ARM7 (ARMv4) to the present) each processor or generation of processors
has added some instructions to the ARM7 instruction set, with maybe only
one or a few exceptions the original ARM7 instruction set is universal
to all ARM processors to date (that support the 32 bit ARM instruction
set).  Thumb-2 instructions are an extension to the thumb instruction
set.  Processors that support thumb-2 support the original thumb
instruction set.  Thumb-2 instructions capitalize on what would be
undefined/illegal instructions in the original thumb instruction set,
in particular adding a second instruction word, making them a total of
32 bits.  But not to be confused with the 32 bit ARM instruction set.  I
consider thumb2 to be a bit of a kludge.  I like the pure fixed
instruction length nature of the classic 32 bit ARM instructions and
these 16 bit thumb instructions.  Thumb-2 is supposed to combine the
code density of thumb with performance of ARM.  Not to say that the
all thumb variant thumb instructions were slow.  The same source
code would require more thumb instructions than the same code compiled
for ARM.  So the thumb version is not exactly half of the ARM version
from the same code, just a little more than half, 5%, 10%, etc depending
on your application of course.  If you are running on a system with
zero wait state 32 bit wide memory, because the ARM code uses fewer
instructions it will execute faster than thumb.  But take a system
like the game boy advance from Nintendo.  Most of the busses and the
rom are 16 bits wide and slow.  An ARM instruction takes two bus
memory cycles compared to a thumb.  In general compiling for thumb
for a Game Boy Advance would produce faster to much faster code than
compiling the same source using ARM instructions.  So you cant make
a general statement like thumb is slower than ARM or faster than
ARM.

What started out as something that was trying to give better code
density (uses less program memory to perform the same task as an ARM
based program) has now, in my opinion, become the portable ARM
instruction set as almost all ARM cores will run the "all thumb variant"
thumb instructions.  This feature more than any other, combined with
ARM processors being the most popular processor (in terms of processors
sold) makes the thumb instruction set (all thumb variant) something
worth learning.

Assume from this point on, all thumb references are assumed to mean
the "all thumb variant" instructions.  Where does this "all thumb
variant" term come from?  Any time you develop software for an ARM
processor it is strongly suggested you download at least two specific
documents.  For both start at http://infocenter.arm.com, the first
is the ARM ARM (ARM Architectural Reference Manual).  Because of the
number of ARM processor architectures now the ARM ARM is multiple
manuals, one for each processor architecture or subset of architecture.
The ARMv5 ARM ARM, is what used to be the unifed ARM ARM.  Along the
left side of the web page find the ARM Architecture section then
the Reference Manuals link.  And for this tutoral the ARMv5 ARM ARM,
in general get the ARM ARM specified by the chip vendor for the product
you are using.  The second document is the TRM (Technical Reference
Manual).  Each ARM core is part of some architecture family and that
ties to the family generic ARM ARM.  The specific details for a core
are in the TRM.  Exactly which new instructions are or are not
supported, exactly what timers or other features are suppored, etc.
For this tutorial you only need the ARMv5 ARM ARM it includes the
thumb instruciton set specification plus a lot about the general
architecture of the ARM processor which can be understood from an
ARM perspective or thumb perspective.

Bear with me we will start programming very soon.

So what do you have to give up when going from 32 bit ARM instructions
to 16 bit thumb instructions?  Well, to keep it simple, first off every
ARM instruction could conditionally execute.  Many processors let you
branch on greater than, with the ARM instructions you could subtract
if greater than, load this register from memory if greater than, etc.
The thunb instruction set, got rid of those bits and only the conditional
branches are conditional.  As part of that ARM feature the ALU instructions
that in most other processors would always modify the processor status
bits, the relevant ARM instructions had a bit in the instruction to
allow or not allow those bits to be changed.  You could perform a
subtract, allowing the processor status bits to be changed, and then
if the zero flag was set then perform an add that did not touch the
flags (did not touch/change the zero flag for example) then perform
a number of other instructions on the condition that the zero
flag was set.  If every alu operation modified the z flag you couldnt
really use this cool ARM instruction set feature of conditions on
every instruction.  Well, as you can guess, thumb is more traditional,
you dont get that extra bit, you cant disable the modification of
flags for instructions like alu instructions that normally modify the
flags.  Another big chunk of bits they squeezed out is mostly limiting
instructions to two operand registers instead of one.  For example
the ARM XOR instruction can essentially perform a = b ^ c (this is NOT
the actual ARM syntax) using three different registers, two operands/inputs
and one result.  With thumb a few instructions support three registers
but most only two, so you can only perform a = a ^ b.  To perform the
three register XOR equivalent you would have to do something like these
two instructions a = b (mov) and a = a ^ c (not the actual thumb
syntax).  Not the last difference, but the last one to mention at this
time is most of the thumb instructions only operate on registers r0-r7.
Basically the last two things mentioned reduced 12 bits (4+4+4) of
instruction required to specify three registers down to 6 bits (3+3) of
instruction required to specify two registers.

Reminder read through the lsasim project tutorial first, then come back
here.

This is a work in progress...






















